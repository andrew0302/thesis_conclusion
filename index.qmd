---
title: "thesis_conclusion"
---

# Conclusion

## The Problem: Ground Truth Needs More Than Good Will

- Despite growing recognition of dataset problems, actual progress toward better ground-truth data practices remains slow.
- Current incentives prioritize speed, performance, and novelty rather than careful measurement design or long-term dataset stewardship.
- The **cost of collecting meaningful, high-quality datasets** — particularly for complex constructs like values, intentions, or intelligence — is **underappreciated and underfunded**. Collecting good data is expensive, but neglecting this cost leads to cascading problems in AI evaluation.
- Without better practices, datasets remain opaque, unexamined, and prone to embedding systemic biases from the start.

## Lessons from Other Fields: Registered Reports and the Science of Measurement

- In fields like psychology and medicine, **Registered Reports** emerged to separate the design of a study from its results, reducing biases like hindsight bias and outcome switching.
- Other fields actively **study how to measure complex constructs**: e.g., psychometrics for cognitive ability, epidemiology for disease burden, and survey methodology for social phenomena.
- These fields show that **developing good measurement instruments** is a dedicated scientific effort — not a side activity.
- If AI research depends critically on ground-truth data, then the field needs a **dedicated research agenda focused on ground-truth design and measurement science**.

## Biases in AGI Research Highlight the Need for Careful Grounding

- In our ICSE-SEIS 2023 paper, we critique **unscientific performance claims** in AGI-related work.
- AGI research is especially vulnerable to confirmation bias, wishful thinking, and premature performance claims without rigorous benchmarks.
- **Defining the constructs we aim to measure** (e.g., "intelligence" in LLMs) must be a scientific task in itself. Intelligence may manifest differently in AI systems than in humans, requiring new conceptualizations and new measurement instruments.
- Without careful construct definition and measurement, claims about AGI capabilities risk being scientifically meaningless.

## Micropublication Models: Capturing Data Collection as a First-Class Output

- Micropublications are modular, peer-reviewed publications that focus on specific research artifacts like datasets, annotation protocols, or measurement plans.
- Extending the Registered Reports model, we can **approve data collection protocols** *before* data is collected, including sampling design, measurement instruments, and annotation strategies.
- Decentralized contributors (e.g., multiple labs or individuals) could **publish individual datasets** under a shared, peer-reviewed protocol.
- This would move ground-truth collection toward **transparent, modular, and cumulative science**, rather than isolated, one-off efforts.

## Building Infrastructure for Transparent Ground Truth

- Our SEIS 2023 paper pushes for open, linked, reproducible artifacts, not just final models or results.
- Our CHI 2023 paper critiques the opacity of machine learning artifacts and calls for linking data, documentation, and transparent evaluation processes.
- **Alexandria**:
  - A web platform combining Wikipedia-style collaborative editing with GitHub-style version control.
  - Supports the **CREDIT taxonomy** for structured contributor recognition.
  - **Proof of concept**: Built almost entirely by student developers under supervision, showing that decentralized academic innovation is possible.
  - A few additional steps would yield a fully operational infrastructure supporting micropublication of ground-truth artifacts.

## The Vision: Toward Responsible Ground Truth for AI and AGI

- Researchers pre-register their ground-truth collection plans, including constructs, instruments, and expected properties of the data.
- Peer-reviewed protocols are made public before data collection.
- Annotators, coders, and dataset curators are properly credited through micropublications.
- Datasets grow openly, collaboratively, with tracked provenance and version control.
- This infrastructure builds **trustworthy, reproducible foundations** for the next generation of AI and AGI research.

## Concluding Call to Action

- The AI/ML research community, conferences, funding agencies, and publishers must recognize ground-truth data creation as a first-class research contribution.
- New formats like data-focused Registered Reports and micropublications should be adopted.
- Better data design enables better science, more responsible innovation, and safer, more meaningful AI systems.
