<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>A Need for a Contemporary Field – thesis_conclusion</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-6bd9cfa162949bde0a231f530c97869d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">thesis_conclusion</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="./index.html" aria-current="page"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#increasing-data-requirements-require-curation" id="toc-increasing-data-requirements-require-curation" class="nav-link active" data-scroll-target="#increasing-data-requirements-require-curation">Increasing data requirements require curation</a></li>
  <li><a href="#increasing-data-quality-requires-focused-study" id="toc-increasing-data-quality-requires-focused-study" class="nav-link" data-scroll-target="#increasing-data-quality-requires-focused-study">Increasing Data Quality Requires Focused Study</a></li>
  <li><a href="#lessons-from-other-fields-registered-reports-and-the-science-of-measurement" id="toc-lessons-from-other-fields-registered-reports-and-the-science-of-measurement" class="nav-link" data-scroll-target="#lessons-from-other-fields-registered-reports-and-the-science-of-measurement">Lessons from Other Fields: Registered Reports and the Science of Measurement</a></li>
  <li><a href="#biases-in-agi-research-highlight-the-need-for-careful-grounding" id="toc-biases-in-agi-research-highlight-the-need-for-careful-grounding" class="nav-link" data-scroll-target="#biases-in-agi-research-highlight-the-need-for-careful-grounding">Biases in AGI Research Highlight the Need for Careful Grounding</a></li>
  <li><a href="#micropublication-models-capturing-data-collection-as-a-first-class-output" id="toc-micropublication-models-capturing-data-collection-as-a-first-class-output" class="nav-link" data-scroll-target="#micropublication-models-capturing-data-collection-as-a-first-class-output">Micropublication Models: Capturing Data Collection as a First-Class Output</a></li>
  <li><a href="#building-infrastructure-for-transparent-ground-truth" id="toc-building-infrastructure-for-transparent-ground-truth" class="nav-link" data-scroll-target="#building-infrastructure-for-transparent-ground-truth">Building Infrastructure for Transparent Ground Truth</a></li>
  <li><a href="#the-vision-toward-responsible-ground-truth-for-ai-and-agi" id="toc-the-vision-toward-responsible-ground-truth-for-ai-and-agi" class="nav-link" data-scroll-target="#the-vision-toward-responsible-ground-truth-for-ai-and-agi">The Vision: Toward Responsible Ground Truth for AI and AGI</a></li>
  <li><a href="#concluding-call-to-action" id="toc-concluding-call-to-action" class="nav-link" data-scroll-target="#concluding-call-to-action">Concluding Call to Action</a></li>
  <li><a href="#sec-appendix" id="toc-sec-appendix" class="nav-link" data-scroll-target="#sec-appendix">Appendix</a>
  <ul class="collapse">
  <li><a href="#appendix-a-citation-trends-plot" id="toc-appendix-a-citation-trends-plot" class="nav-link" data-scroll-target="#appendix-a-citation-trends-plot">Appendix A: Citation Trends Plot</a></li>
  <li><a href="#appendix-b-search-terms" id="toc-appendix-b-search-terms" class="nav-link" data-scroll-target="#appendix-b-search-terms">Appendix B: Search terms</a>
  <ul class="collapse">
  <li><a href="#scopus" id="toc-scopus" class="nav-link" data-scroll-target="#scopus">SCOPUS:</a></li>
  <li><a href="#arxiv" id="toc-arxiv" class="nav-link" data-scroll-target="#arxiv">arXiv:</a></li>
  </ul></li>
  <li><a href="#appendix-c-token-estimates" id="toc-appendix-c-token-estimates" class="nav-link" data-scroll-target="#appendix-c-token-estimates">Appendix C: Token estimates</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="index.docx"><i class="bi bi-file-word"></i>MS Word</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">A Need for a Contemporary Field</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>AI systems are a direct product of the data used to train and evaluate them. We shape the behavior of AI systems with the processes we use to design, gather, analyze, and report the training and evaluation data. Work over the past decade has emerged explaining limitations of commonly re-used datasets, with many commonly used ‘benchmark’ datasets showing a lack of representativeness <span class="citation" data-cites="hullman2022worst">(<a href="#ref-hullman2022worst" role="doc-biblioref">Hullman et al., 2022</a>)</span>, measurement quality <span class="citation" data-cites="jacobs2021measurement">(<a href="#ref-jacobs2021measurement" role="doc-biblioref">Jacobs &amp; Wallach, 2021</a>)</span>, accounting for the full range of reasonable interpretations in terms of annotations <span class="citation" data-cites="cabitza2023toward">(<a href="#ref-cabitza2023toward" role="doc-biblioref">Cabitza et al., 2023</a>)</span>, and completeness in reporting of the annotation process <span class="citation" data-cites="geiger2020garbage geiger2021garbage">(<a href="#ref-geiger2020garbage" role="doc-biblioref">Geiger et al., 2020</a>, <a href="#ref-geiger2021garbage" role="doc-biblioref">2021</a>)</span>. Although improvements to data collection processes have been proposed, they are at best slowly being adopted, and at worst being largely ignored. The increasingly sophisticated systems we build have an accompanying cost not only in terms of sheer training data size, but also in the labor required to curate it (e.g.&nbsp;large language models)<span class="citation" data-cites="kandpal2025position">(<a href="#ref-kandpal2025position" role="doc-biblioref">Kandpal &amp; Raffel, 2025</a>)</span>. This is exacerbated by the increasingly sophisticated qualities we aim to evaluate systems on, that in turn are challenging to define and measure (e.g.&nbsp;‘fairness’) <span class="citation" data-cites="jacobs2021measurement">(<a href="#ref-jacobs2021measurement" role="doc-biblioref">Jacobs &amp; Wallach, 2021</a>)</span>. Furthermore, the human-like behavior of the sophisticated systems we are evaluating are a prime target for anthropomorphistically biased mis-interpretations of their outputs, as many aim to behave similar to humans <span class="citation" data-cites="altmeyer2024position">(<a href="#ref-altmeyer2024position" role="doc-biblioref">Altmeyer et al., 2024</a>)</span>.</p>
<p>The future qualities of AI systems will be shaped by the data practices we establish today: the degree to which we invest in better design, collection, and analysis of training and evaluation data will determine the real-world performance of the AI systems we will build. It is thus crucial that we put in place better practices. However, improving how the field collects benchmark data requires substantial efforts beyond the already substantial efforts invested. As an example, the case study in this thesis proposes enriching design, collection, analysis, and reporting of training/evaluation data for AI systems, using knowledge from the social sciences <span class="citation" data-cites="beck2022improving">Jacobs &amp; Wallach (<a href="#ref-jacobs2021measurement" role="doc-biblioref">2021</a>)</span>, metrology (measurement science) <span class="citation" data-cites="welty2019metrology">(<a href="#ref-welty2019metrology" role="doc-biblioref">Welty et al., 2019</a>)</span>, and work in the computational sciences on ‘ground-truthing’ <span class="citation" data-cites="cabitza2023toward">(<a href="#ref-cabitza2023toward" role="doc-biblioref">Cabitza et al., 2023</a>)</span>. It requires <em>a-priori</em> empirical investigation of the data collection process in addition to the data collection process itself, in principle for every combination of <em>construct</em> (i.e.&nbsp;the latent phenomenon of interest being measured), <em>content</em> (e.g.&nbsp;text, video, audio etc. and in some cases also subgroups, e.g.&nbsp;tweets vs.&nbsp;podcast transcripts vs.&nbsp;formal speeches etc.), and for relevant <em>characteristics</em> of annotators (i.e.&nbsp;ethnicity, political affiliation, etc.). Open questions remain for the primary case-study as well as for the field as a whole, all of which anticipate future studies, and by extension further efforts.</p>
<p>Questions remain as to how AI research as it is currently conducted can implement these solutions. As it stands, our current knowledge gathering apparatus - science as it is now practiced and reported - is overburdened. The ever increasing volume of published manuscripts on AI and related topics<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> makes it impossible to stay abreast of the overall field: 10% of over 4 million publications indexed on the SCOPUS academic database in 2024, up from around 7% in 2022, had terms related to AI in their title, keywords or abstracts (see Appendix A). The number of submitted manuscripts also increases year over year, with popular conferences like NeurIPS receiving upwards of 12k submissions in 2023<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. This makes it more and more difficult to find reviewers, and by extension to monitor the overall quality of the field <span class="citation" data-cites="Zhang_2022">(<a href="#ref-Zhang_2022" role="doc-biblioref">Zhang et al., 2022</a>)</span>. These figures do not include preprints posted on servers like arXiv, which show over 42k works with AI related terms in the abstract for 2024, more than doubling the about 17.5k posts in 2019. PhD candidates, who contribute a substantial proportion of academic work <span class="citation" data-cites="lariviere2012shoulders">(<a href="#ref-lariviere2012shoulders" role="doc-biblioref">Larivière, 2012</a>)</span>, are bogged down by requirements to write and defend theses despite the decreasing trend of thesis citations over time <span class="citation" data-cites="lariviere2008declining">(<a href="#ref-lariviere2008declining" role="doc-biblioref">Larivière et al., 2008</a>)</span>, and evidence that PhD candidates with fixed duration contracts exceed that duration by several months, resorting to completing their thesis on their own time and risking failing at completion <span class="citation" data-cites="van2013took">(<a href="#ref-van2013took" role="doc-biblioref">Van de Schoot et al., 2013</a>)</span>. Further, publications, and not theses, remain the key factor in the assesment of their value as scientists <span class="citation" data-cites="anderson2022effect">(<a href="#ref-anderson2022effect" role="doc-biblioref">Anderson et al., 2022</a>)</span> - efforts which could be put towards meeting some of this labor gap. Predictably, academics appear to be turning to Large Language Models for assistance, as use is showing in academic work in both peer reviews <span class="citation" data-cites="liang2024monitoring">(<a href="#ref-liang2024monitoring" role="doc-biblioref">Liang et al., 2024</a>)</span>, and in manuscripts <span class="citation" data-cites="gray2024chatgpt">(<a href="#ref-gray2024chatgpt" role="doc-biblioref">Gray, 2024</a>)</span>. This overburden raises questions beyond the poor evaluation of the models that underlie ‘AI’ to the ‘AI’ research process itself, as well as to its likelihood of applying improvements.</p>
<p>This conclusiory manuscript thus highlights the crucial challenge for academic study of AI in the coming decade: developing an infrastructure that allows for the study of AI, including the data that are its raw materials, with little - or at the very least, substantially less - harmful bias. It highlights the need for identifiable academic publication venues that gather works on the study of ground-truthing, more modern publication formats that allow for dataset requirements to be studied prior to their collection, and for infrastructure that allows the burden of their collection to be distributed among stakeholders. It concludes that, while works like the case study embedded in this thesis are necessary, the various fields studying topics related to AI are poorly positioned to implement them.</p>
<section id="increasing-data-requirements-require-curation" class="level2">
<h2 class="anchored" data-anchor-id="increasing-data-requirements-require-curation">Increasing data requirements require curation</h2>
<p>Contemporary training methods require increasingly large amounts of training data. Taking the development of Large Language Models as a use-case, the training dataset for Llama 3 included 15T tokens, up from 2T for Llama 2. Although not all details of the datasets have been shared, and setting aside questions of copywrite, licensing, and ethical concerns, any available text that is likely to have some quality is limited compared to these requirements. Among the refined sources of text available, Wikipedia, which comprises some 6.9M English articles, comprised of approximately 62M pages, is an estimated 5 billion tokens<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. If we take the approximate 4.4M papers published in 2024 and indexed on Scopus as an indication, academia published an estimated 45B tokens in that year. If we extend our reach to other repositories, e.g.&nbsp;the approximately 88.3 million academic papers available on Sci-hub would result in an approximate upper boundary of estimate 700B or so. A similar figure might be estimated from libegen and the 7.5M<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> books there. While academic pursuits clearly result in increasing token counts, we have immediate access to a set of approximately 1.5T. Internet archive has some 44M books, which may yield up to 4.4T, although we expect duplicates with the libgen archive. Thus, a more likely source for the ever-increasing data requirements are repositories like Common Crawl<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. But this too has limits, and we are projected to have too little human-generated text to continue the increase in model size this decade <span class="citation" data-cites="villalobos2024position">(<a href="#ref-villalobos2024position" role="doc-biblioref">Villalobos et al., 2024</a>)</span>.</p>
<p>The largest frontier models cost tens of millions of USD to train, with estimates of GPT-4 at 40M USD for hardware (chips, servers, and networking hardware) and energy, and estimated increases of 2.4 X per year suggesting that frontier models will cost 1B USD to train by 2027 <span class="citation" data-cites="cottier2024rising">(<a href="#ref-cottier2024rising" role="doc-biblioref">Cottier et al., 2024</a>)</span>. Notably, this cost exceeds annual revenues in companies training large scale LLMs <span class="citation" data-cites="kandpal2025position">(<a href="#ref-kandpal2025position" role="doc-biblioref">Kandpal &amp; Raffel, 2025</a>)</span>. Human labor responsible for the collection, curation, and eventual annotation of training data in addition to the training of the model (including researchers, engineers, and managers, but not data center employees and operations staff) is estimated at 29%-49% of the overall cost <span class="citation" data-cites="cottier2024rising">(<a href="#ref-cottier2024rising" role="doc-biblioref">Cottier et al., 2024</a>)</span>. Notably, these cost calculations ignore the cost of producing the text itself, and though its value is difficult to calculate, estimates range from 10-1000 X more than the total cost of the training of the models <span class="citation" data-cites="kandpal2025position">(<a href="#ref-kandpal2025position" role="doc-biblioref">Kandpal &amp; Raffel, 2025</a>)</span>. In other words, the more valuable thing is the data and not the model, and the lack of appropriate compensation for its use has given rise to a number of lawsuits (e.g.&nbsp;Authors Guild vs.&nbsp;OpenAI <a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>).</p>
<p>Thus, the field of AI must wrestle with two opposing issues: we want to train them with data that has high quality - e.g we want the data to be representative of conditions where the model will be deployed, and thus relevant distributions in the training data must reflect the environment in which the models will be deployed <span class="citation" data-cites="hullman2022worst">(<a href="#ref-hullman2022worst" role="doc-biblioref">Hullman et al., 2022</a>)</span>, but the data requirements to train them appear thus far to be ever-increasing <span class="citation" data-cites="villalobos2024position">(<a href="#ref-villalobos2024position" role="doc-biblioref">Villalobos et al., 2024</a>)</span>. We want the data used in training to be ‘good’ because we want the models to be ‘trustworthy’ - in the case of LLMs, we want to have reason to think they will generate text that includes claims that we think are true. Perhaps our closest approximation to ‘what we think is true’ is contained the overall perspective presented in all of academic work - the estimating probability of the truth of potential explanations given carefully collected and analyzed observations. And yet, even if there were little to no barriers to using all of human academic text to train LLMs, this amount of text pales in quantity to the vastness of crawled text on the internet. Thus the creation and curation of load-bearing training datasets is a central issue, despite the overwhelming focus on algorithmic work <span class="citation" data-cites="birhane2022values">(<a href="#ref-birhane2022values" role="doc-biblioref">Birhane et al., 2022</a>)</span>.</p>
</section>
<section id="increasing-data-quality-requires-focused-study" class="level2">
<h2 class="anchored" data-anchor-id="increasing-data-quality-requires-focused-study">Increasing Data Quality Requires Focused Study</h2>
<p>Datasets for evaluation very often contain human input <span class="citation" data-cites="geiger2020garbage geiger2021garbage">(<a href="#ref-geiger2020garbage" role="doc-biblioref">Geiger et al., 2020</a>, <a href="#ref-geiger2021garbage" role="doc-biblioref">2021</a>)</span>. Unlike the field of Machine Learning, other disciplines (psychology, economics, software engineering) have entire fields dedicated to the design, collection, analysis, and reporting of data that involves human behavior (psychometrics, econometrics, software testing). Despite growing recognition of dataset problems <span class="citation" data-cites="hullman2022worst">(<a href="#ref-hullman2022worst" role="doc-biblioref">Hullman et al., 2022</a>)</span>, which in turn have the potential to lead to harms <span class="citation" data-cites="mehrabi2021survey">(<a href="#ref-mehrabi2021survey" role="doc-biblioref">Mehrabi et al., 2021</a>)</span>, actual progress toward better ground-truth data practices, from collection, to analysis remains slow. Current incentives prioritize accuracy and efficiency rather than careful measurement design or long-term dataset stewardship <span class="citation" data-cites="birhane2022values">(<a href="#ref-birhane2022values" role="doc-biblioref">Birhane et al., 2022</a>)</span>.</p>
<p>When collecting annotations, labels, or other forms of input from people in order to construct training/evaluation datasets, we are attempting to collect measurements of latent, unobservable <em>constructs</em> <span class="citation" data-cites="jacobs2021measurement">(<a href="#ref-jacobs2021measurement" role="doc-biblioref">Jacobs &amp; Wallach, 2021</a>)</span>. In other words, when we consider the input from multiple people in aggregate, we do not directly observe e.g.&nbsp;the presence or absence of an object in a digital image; rather we observe the probability that a person from a given population will indicate the presence of absence of the object in the image <span class="citation" data-cites="welty2019metrology">(<a href="#ref-welty2019metrology" role="doc-biblioref">Welty et al., 2019</a>)</span>. In the parlance of psychology, one cannot directly observe an other’s Extraversion score, as one might observe an other’s height. Although height is observable, our measurements of it are still imperfect: in using a measurement device like a ruler multiple times, should we measure precisely enough, we would like observe variance in each measurement, with the true score for height imperfectly represented by our imperfect measurements <span class="citation" data-cites="welty2019metrology">(<a href="#ref-welty2019metrology" role="doc-biblioref">Welty et al., 2019</a>)</span>.</p>
<p>Any standardized procedure for comparing two or more individuals is treated like a measurement instrument in the social sciences <span class="citation" data-cites="urbina2014essentials">(<a href="#ref-urbina2014essentials" role="doc-biblioref">Urbina, 2014</a>)</span>. The repeatable procedures that we use to gather annotations are similarly measurement instruments <span class="citation" data-cites="beck2022improving">(<a href="#ref-beck2022improving" role="doc-biblioref">Beck et al., 2022</a>)</span>. Given the complexity of measuring unobservable phenomena, instruments are subjected to scrutiny prior to being considered usable for their intended purpose. The process of <em>construct validation</em> involves estimating the extent to which an instrument measures an unobservable construct <span class="citation" data-cites="Wehner2020">(<a href="#ref-Wehner2020" role="doc-biblioref">Wehner et al., 2020</a>)</span>. It assumes an unknowable true score, and that all attempts to measure the true score are imperfect. Thus there is no single solution to demonstrating the validity of a construct, but rather an accumulation of evidence, across multiple studies, with observations made using different methods <span class="citation" data-cites="smith2005construct">(<a href="#ref-smith2005construct" role="doc-biblioref">Smith, 2005</a>)</span>. Thus, by extension the datasets that we collect and use to benchmark the performance of models, are similarly measurement instruments <span class="citation" data-cites="welty2019metrology">(<a href="#ref-welty2019metrology" role="doc-biblioref">Welty et al., 2019</a>)</span>.</p>
<p>The <strong>cost of collecting meaningful, high-quality datasets</strong> — particularly for complex constructs like values, intentions, or intelligence — is <strong>underappreciated and underfunded</strong>. [Thesis contributions here.] Whether a simple or complex ground-truthing problem, treating the phenomenon of interest like a construct has benefits. Collecting good data is expensive, but neglecting this cost leads to cascading problems in AI evaluation.</p>
<p>Without better practices, datasets remain opaque, unexamined, and prone to embedding systemic biases from the start.</p>
</section>
<section id="lessons-from-other-fields-registered-reports-and-the-science-of-measurement" class="level2">
<h2 class="anchored" data-anchor-id="lessons-from-other-fields-registered-reports-and-the-science-of-measurement">Lessons from Other Fields: Registered Reports and the Science of Measurement</h2>
<ul>
<li>In fields like psychology and medicine, <strong>Registered Reports</strong> emerged to separate the design of a study from its results, reducing biases like hindsight bias and outcome switching.</li>
<li>Other fields actively <strong>study how to measure complex constructs</strong>: e.g., psychometrics for cognitive ability, epidemiology for disease burden, and criminology for recidivism. These fields show that <strong>developing good measurement instruments</strong> is a dedicated scientific effort — not a side activity.</li>
<li>If AI research depends critically on ground-truth data, then the field needs a <strong>dedicated research agenda focused on ground-truth design and measurement science</strong>. Beyond lessons learned in other fields are ground-truthing specific questions.</li>
</ul>
</section>
<section id="biases-in-agi-research-highlight-the-need-for-careful-grounding" class="level2">
<h2 class="anchored" data-anchor-id="biases-in-agi-research-highlight-the-need-for-careful-grounding">Biases in AGI Research Highlight the Need for Careful Grounding</h2>
<ul>
<li>In our ICSE-SEIS 2023 paper, we critique <strong>unscientific performance claims</strong> in AGI-related work.</li>
<li>AGI research is especially vulnerable to confirmation bias, wishful thinking, and premature performance claims without rigorous benchmarks.</li>
<li><strong>Defining the constructs we aim to measure</strong> (e.g., “intelligence” in LLMs) must be a scientific task in itself. Intelligence may manifest differently in AI systems than in humans, requiring new conceptualizations and new measurement instruments.</li>
<li>Without careful construct definition and measurement, claims about AGI capabilities risk being scientifically meaningless.</li>
</ul>
</section>
<section id="micropublication-models-capturing-data-collection-as-a-first-class-output" class="level2">
<h2 class="anchored" data-anchor-id="micropublication-models-capturing-data-collection-as-a-first-class-output">Micropublication Models: Capturing Data Collection as a First-Class Output</h2>
<ul>
<li>Micropublications are modular, peer-reviewed publications that focus on specific research artifacts like datasets, annotation protocols, or measurement plans.</li>
<li>Extending the Registered Reports model, we can <strong>approve data collection protocols</strong> <em>before</em> data is collected, including sampling design, measurement instruments, and annotation strategies.</li>
<li>Decentralized contributors (e.g., multiple labs or individuals) could <strong>publish individual datasets</strong> under a shared, peer-reviewed protocol.</li>
<li>This would move ground-truth collection toward <strong>transparent, modular, and cumulative science</strong>, rather than isolated, one-off efforts.</li>
</ul>
</section>
<section id="building-infrastructure-for-transparent-ground-truth" class="level2">
<h2 class="anchored" data-anchor-id="building-infrastructure-for-transparent-ground-truth">Building Infrastructure for Transparent Ground Truth</h2>
<ul>
<li>Our SEIS 2023 paper pushes for open, linked, reproducible artifacts, not just final models or results.</li>
<li>Our CHI 2023 paper critiques the opacity of machine learning artifacts and calls for linking data, documentation, and transparent evaluation processes.</li>
<li><strong>Alexandria</strong>:
<ul>
<li>A web platform combining Wikipedia-style collaborative editing with GitHub-style version control.</li>
<li>Supports the <strong>CREDIT taxonomy</strong> for structured contributor recognition.</li>
<li><strong>Proof of concept</strong>: Built almost entirely by student developers under supervision, showing that decentralized academic innovation is possible.</li>
<li>A few additional steps would yield a fully operational infrastructure supporting micropublication of ground-truth artifacts.</li>
</ul></li>
</ul>
</section>
<section id="the-vision-toward-responsible-ground-truth-for-ai-and-agi" class="level2">
<h2 class="anchored" data-anchor-id="the-vision-toward-responsible-ground-truth-for-ai-and-agi">The Vision: Toward Responsible Ground Truth for AI and AGI</h2>
<ul>
<li>Researchers pre-register their ground-truth collection plans, including constructs, instruments, and expected properties of the data.</li>
<li>Peer-reviewed protocols are made public before data collection.</li>
<li>Annotators, coders, and dataset curators are properly credited through micropublications.</li>
<li>Datasets grow openly, collaboratively, with tracked provenance and version control.</li>
<li>This infrastructure builds <strong>trustworthy, reproducible foundations</strong> for the next generation of AI and AGI research.</li>
</ul>
</section>
<section id="concluding-call-to-action" class="level2">
<h2 class="anchored" data-anchor-id="concluding-call-to-action">Concluding Call to Action</h2>
<ul>
<li>The AI/ML research community, conferences, funding agencies, and publishers must recognize ground-truth data creation as a first-class research contribution.</li>
<li>New formats like data-focused Registered Reports and micropublications should be adopted.</li>
<li>Better data design enables better science, more responsible innovation, and safer, more meaningful AI systems.</li>
</ul>
<p>It’s the ‘real’ world of publication that matters. As <span class="citation" data-cites="lariviere2012shoulders">Larivière (<a href="#ref-lariviere2012shoulders" role="doc-biblioref">2012</a>)</span> note, a thesis defense is a more curated experience as the ‘peer reviewers’ are chosen by the supervisors of the student - on the other hand, peer reviewers in the world of academic publication are far broader than the networks of the PhD candidate’s supervisory staff. One study in Canada in 2012 showed that one third of all academic output comes form PhD students <span class="citation" data-cites="lariviere2012shoulders">(<a href="#ref-lariviere2012shoulders" role="doc-biblioref">Larivière, 2012</a>)</span>. One study showed the decline of citations of PhD theses over time <span class="citation" data-cites="lariviere2008declining">(<a href="#ref-lariviere2008declining" role="doc-biblioref">Larivière et al., 2008</a>)</span>. Perhaps there are other, more productive ways to contribute rather than taking the time to write a thesis.</p>
</section>
<section id="sec-appendix" class="level1">
<h1>Appendix</h1>
<section id="appendix-a-citation-trends-plot" class="level2">
<h2 class="anchored" data-anchor-id="appendix-a-citation-trends-plot">Appendix A: Citation Trends Plot</h2>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/publication_plots-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="appendix-b-search-terms" class="level2">
<h2 class="anchored" data-anchor-id="appendix-b-search-terms">Appendix B: Search terms</h2>
<section id="scopus" class="level3">
<h3 class="anchored" data-anchor-id="scopus">SCOPUS:</h3>
<p>for AI related topics: TITLE-ABS-KEY ( ( ( ( machine OR deep OR reinforcement OR supervised OR unsupervised ) AND learning ) OR ( “neural networks” ) OR ( ai OR “artificial intelligence” ) ) ) AND PUBYEAR &gt; 1999 AND PUBYEAR &lt; 2027</p>
<p>for overall publication records: PUBYEAR &gt; 1999 AND PUBYEAR &lt; 2027</p>
</section>
<section id="arxiv" class="level3">
<h3 class="anchored" data-anchor-id="arxiv">arXiv:</h3>
<p>[Abstract] AI or “artificial intelligence” OR machine AND learning OR supervised AND learning OR reinforcement AND learning OR neural AND networks</p>
<p>17,459 results in 2019 23,923 results in 2020 27,610 results in 2021 29,690 results in 2022 33,419 results in 2023 42,183 in 2024</p>
</section>
</section>
<section id="appendix-c-token-estimates" class="level2">
<h2 class="anchored" data-anchor-id="appendix-c-token-estimates">Appendix C: Token estimates</h2>
<p>Taking a study on the word length requirements of education journals as a proxy, <span class="citation" data-cites="fairbairn2009profile">Fairbairn et al. (<a href="#ref-fairbairn2009profile" role="doc-biblioref">2009</a>)</span> report the following figures:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/token_counts-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate midpoints for each bin</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>midpoints <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2500</span>, <span class="dv">3450</span>, <span class="dv">4450</span>, <span class="dv">5450</span>, <span class="dv">6450</span>, <span class="dv">7450</span>, <span class="dv">8450</span>, <span class="dv">9500</span>, <span class="dv">10500</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Add midpoints to the dataframe</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>paper_lengths<span class="sc">$</span>Midpoint <span class="ot">&lt;-</span> midpoints</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate mean token count</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>mean_est <span class="ot">&lt;-</span> <span class="fu">sum</span>(paper_lengths<span class="sc">$</span>Midpoint <span class="sc">*</span> paper_lengths<span class="sc">$</span>Count) <span class="sc">/</span> <span class="fu">sum</span>(paper_lengths<span class="sc">$</span>Count)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate weighted variance</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>var_est <span class="ot">&lt;-</span> <span class="fu">sum</span>(paper_lengths<span class="sc">$</span>Count <span class="sc">*</span> (paper_lengths<span class="sc">$</span>Midpoint <span class="sc">-</span> mean_est)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> <span class="fu">sum</span>(paper_lengths<span class="sc">$</span>Count)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Take square root to get standard deviation</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>sd_est <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(var_est)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Print result</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="fu">paste</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>character(0)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"SD words: "</span>, sd_est))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "SD words:  1925.27260683454"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Mean words: "</span>, mean_est))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Mean words:  6342.166344294"</code></pre>
</div>
</div>
<p>https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them?utm_source=chatgpt.com According to Open AI, a token is 3/4 of a word</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>sd_tokens <span class="ot">&lt;-</span> sd_est<span class="sc">*</span><span class="fl">1.25</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>mean_tokens <span class="ot">&lt;-</span> mean_est<span class="sc">*</span><span class="fl">1.25</span> </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"SD Tokens: "</span>, <span class="fu">round</span>(sd_tokens, <span class="dv">2</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "SD Tokens:  2406.59"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Mean Tokens: "</span>, <span class="fu">round</span>(mean_tokens, <span class="dv">2</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Mean Tokens:  7927.71"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">paste</span>( <span class="fu">round</span>(((mean_tokens<span class="sc">-</span>sd_tokens) <span class="sc">*</span> <span class="dv">4500000</span>) <span class="sc">/</span> <span class="dv">1000000000</span>, <span class="dv">2</span>), </span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>       <span class="st">" Billion to"</span>, </span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>       <span class="fu">round</span> (((mean_tokens<span class="sc">+</span>sd_tokens) <span class="sc">*</span> <span class="dv">4500000</span>) <span class="sc">/</span> <span class="dv">1000000000</span>, <span class="dv">2</span>), </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>       <span class="st">"Billion tokens per year from academia."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "24.85  Billion to 46.5 Billion tokens per year from academia."</code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">paste</span>( <span class="fl">4.8</span><span class="sc">*</span><span class="fl">1.25</span>, <span class="st">"Billion tokens from Wikipedia."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "6 Billion tokens from Wikipedia."</code></pre>
</div>
</div>
<p>Wikipedia: https://en.wikipedia.org/wiki/Wikipedia%3ASize_of_Wikipedia?utm_source=chatgpt.com</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="dv">5000000000</span><span class="sc">/</span><span class="dv">2000000000000</span><span class="sc">*</span><span class="dv">100</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.25</code></pre>
</div>
</div>
<p>Sci Hub: https://www.sci-hub.mk/ 88343822 documents as of 9 May 2025 13:47.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>(<span class="fl">7927.71</span> <span class="sc">*</span> <span class="dv">88343822</span>) <span class="sc">/</span> <span class="dv">1000000000</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 700.3642</code></pre>
</div>
</div>
<p>https://www.theatlantic.com/technology/archive/2025/03/libgen-meta-openai/682093/ LibGen</p>
<p>7.5 million books and 81 million research papers.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># at about 100k words per book</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>(<span class="dv">100000</span><span class="sc">*</span><span class="dv">7500000</span>) <span class="sc">/</span> <span class="dv">1000000000</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 750</code></pre>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>(<span class="dv">100000</span><span class="sc">*</span><span class="dv">44000000</span>) <span class="sc">/</span> <span class="dv">1000000000</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4400</code></pre>
</div>
</div>
<p>Llama 2 was 2T tokens, Llama 3 was 15T. I didn’t really see where they got their data from. So I made some guesses.</p>
<p>Looked at Wiki. The whole thing is like 5B.</p>
<p>Sci-Hub, 88.3M papers, which at 8kish tokens is an upper boundary of 700B or so.</p>
<p>7.5 million books on libgen you get about another 700B or so, at 100k-ish per words.</p>
<p>Internet archive has some 44 <strong>million</strong> books. 4.4T.</p>



</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-altmeyer2024position" class="csl-entry" role="listitem">
Altmeyer, P., Demetriou, A. M., Bartlett, A., &amp; Liem, C. (2024). Position: Stop making unscientific AGI performance claims. <em>arXiv Preprint arXiv:2402.03962</em>.
</div>
<div id="ref-anderson2022effect" class="csl-entry" role="listitem">
Anderson, C. G., McQuaid, R. W., &amp; Wood, A. M. (2022). The effect of journal metrics on academic resume assessment. <em>Studies in Higher Education</em>, <em>47</em>(11), 2310–2322.
</div>
<div id="ref-beck2022improving" class="csl-entry" role="listitem">
Beck, J., Eckman, S., Chew, R., &amp; Kreuter, F. (2022). Improving labeling through social science insights: Results and research agenda. <em>International Conference on Human-Computer Interaction</em>, 245–261.
</div>
<div id="ref-birhane2022values" class="csl-entry" role="listitem">
Birhane, A., Kalluri, P., Card, D., Agnew, W., Dotan, R., &amp; Bao, M. (2022). The values encoded in machine learning research. <em>Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency</em>, 173–184.
</div>
<div id="ref-cabitza2023toward" class="csl-entry" role="listitem">
Cabitza, F., Campagner, A., &amp; Basile, V. (2023). Toward a perspectivist turn in ground truthing for predictive computing. <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, <em>37</em>, 6860–6868.
</div>
<div id="ref-cottier2024rising" class="csl-entry" role="listitem">
Cottier, B., Rahman, R., Fattorini, L., Maslej, N., Besiroglu, T., &amp; Owen, D. (2024). The rising costs of training frontier AI models. <em>arXiv Preprint arXiv:2405.21015</em>.
</div>
<div id="ref-fairbairn2009profile" class="csl-entry" role="listitem">
Fairbairn, H., Holbrook, A., Bourke, S., Preston, G., Cantwell, R., &amp; Scevak, J. (2009). A profile of education journals. <em>AARE 2008 International Educational Research Conference</em>, 1–20.
</div>
<div id="ref-geiger2021garbage" class="csl-entry" role="listitem">
Geiger, R. S., Cope, D., Ip, J., Lotosh, M., Shah, A., Weng, J., &amp; Tang, R. (2021). " garbage in, garbage out" revisited: What do machine learning application papers report about human-labeled training data? <em>arXiv Preprint arXiv:2107.02278</em>.
</div>
<div id="ref-geiger2020garbage" class="csl-entry" role="listitem">
Geiger, R. S., Yu, K., Yang, Y., Dai, M., Qiu, J., Tang, R., &amp; Huang, J. (2020). Garbage in, garbage out? Do machine learning application papers in social computing report where human-labeled training data comes from? <em>Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency</em>, 325–336.
</div>
<div id="ref-gray2024chatgpt" class="csl-entry" role="listitem">
Gray, A. (2024). ChatGPT" contamination": Estimating the prevalence of LLMs in the scholarly literature. <em>arXiv Preprint arXiv:2403.16887</em>.
</div>
<div id="ref-hullman2022worst" class="csl-entry" role="listitem">
Hullman, J., Kapoor, S., Nanayakkara, P., Gelman, A., &amp; Narayanan, A. (2022). The worst of both worlds: A comparative analysis of errors in learning from data in psychology and machine learning. <em>Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society</em>, 335–348.
</div>
<div id="ref-jacobs2021measurement" class="csl-entry" role="listitem">
Jacobs, A. Z., &amp; Wallach, H. (2021). Measurement and fairness. <em>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em>, 375–385.
</div>
<div id="ref-kandpal2025position" class="csl-entry" role="listitem">
Kandpal, N., &amp; Raffel, C. (2025). Position: The most expensive part of an LLM should be its training data. <em>arXiv Preprint arXiv:2504.12427</em>.
</div>
<div id="ref-lariviere2012shoulders" class="csl-entry" role="listitem">
Larivière, V. (2012). On the shoulders of students? The contribution of PhD students to the advancement of knowledge. <em>Scientometrics</em>, <em>90</em>(2), 463–481.
</div>
<div id="ref-lariviere2008declining" class="csl-entry" role="listitem">
Larivière, V., Zuccala, A., &amp; Archambault, É. (2008). The declining scientific impact of theses: Implications for electronic thesis and dissertation repositories and graduate studies. <em>Scientometrics</em>, <em>74</em>(1), 109–121.
</div>
<div id="ref-liang2024monitoring" class="csl-entry" role="listitem">
Liang, W., Izzo, Z., Zhang, Y., Lepp, H., Cao, H., Zhao, X., Chen, L., Ye, H., Liu, S., Huang, Z., et al. (2024). Monitoring ai-modified content at scale: A case study on the impact of chatgpt on ai conference peer reviews. <em>arXiv Preprint arXiv:2403.07183</em>.
</div>
<div id="ref-mehrabi2021survey" class="csl-entry" role="listitem">
Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., &amp; Galstyan, A. (2021). A survey on bias and fairness in machine learning. <em>ACM Computing Surveys (CSUR)</em>, <em>54</em>(6), 1–35.
</div>
<div id="ref-smith2005construct" class="csl-entry" role="listitem">
Smith, G. T. (2005). On construct validity: Issues of method and measurement. <em>Psychological Assessment</em>, <em>17</em>(4), 396.
</div>
<div id="ref-urbina2014essentials" class="csl-entry" role="listitem">
Urbina, S. (2014). <em>Essentials of psychological testing</em>. John Wiley &amp; Sons.
</div>
<div id="ref-van2013took" class="csl-entry" role="listitem">
Van de Schoot, R., Yerkes, M. A., Mouw, J. M., &amp; Sonneveld, H. (2013). What took them so long? Explaining PhD delays among doctoral candidates. <em>PloS One</em>, <em>8</em>(7), e68839.
</div>
<div id="ref-villalobos2024position" class="csl-entry" role="listitem">
Villalobos, P., Ho, A., Sevilla, J., Besiroglu, T., Heim, L., &amp; Hobbhahn, M. (2024). Position: Will we run out of data? Limits of LLM scaling based on human-generated data. <em>Forty-First International Conference on Machine Learning</em>.
</div>
<div id="ref-Wehner2020" class="csl-entry" role="listitem">
Wehner, C., Roemer, L., &amp; Ziegler, M. (2020). Construct validity. In V. Zeigler-Hill &amp; T. K. Shackelford (Eds.), <em>Encyclopedia of personality and individual differences</em> (pp. 875–878). Springer International Publishing. <a href="https://doi.org/10.1007/978-3-319-24612-3_1288">https://doi.org/10.1007/978-3-319-24612-3_1288</a>
</div>
<div id="ref-welty2019metrology" class="csl-entry" role="listitem">
Welty, C., Paritosh, P., &amp; Aroyo, L. (2019). Metrology for AI: From benchmarks to instruments. <em>arXiv Preprint arXiv:1911.01875</em>.
</div>
<div id="ref-Zhang_2022" class="csl-entry" role="listitem">
Zhang, Y., Yu, F.-Y., Schoenebeck, G., &amp; Kempe, D. (2022). A system-level analysis of conference peer review. <em>Proceedings of the 23rd ACM Conference on Economics and Computation</em>, 1041–1080. <a href="https://doi.org/10.1145/3490486.3538235">https://doi.org/10.1145/3490486.3538235</a>
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>terms included AI, artificial intelligence, machine learning, and neural networks. See Appendix for specific search strings.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>https://github.com/tranhungnghiep/AI-Conference-Info?utm_source=chatgpt.com<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>According to <a href="https://en.wikipedia.org/wiki/Wikipedia:Size_of_Wikipedia#:~:text=Monthly%20statistics-,Number%20of%20pages,pages%20are%20created%20than%20articles.">wikipedia</a> at 9 May, 2025.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>According to <a href="https://www.theatlantic.com/technology/archive/2025/03/libgen-meta-openai/682093/LibGen">The Atlantic</a>.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>https://commoncrawl.org/<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>https://authorsguild.org/app/uploads/2023/12/Authors-Guild-OpenAI-Microsoft-Class-Action-Complaint-Dec-2023.pdf<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>